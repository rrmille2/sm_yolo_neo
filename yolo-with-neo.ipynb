{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed up YOLOv4 inference to twice as fast on Amazon SageMaker\n",
    "From the blog post found here:   \n",
    "https://aws.amazon.com/blogs/machine-learning/speed-up-yolov4-inference-to-twice-as-fast-on-amazon-sagemaker/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# make sure we have the latest version of sagemaker installed\n",
    "!pip install sagemaker --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import boto3\n",
    "import os\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.session.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.13 |Anaconda, Inc.| (default, Feb 23 2021, 21:15:04) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-21 19:31:12--  https://aws-ml-blog-artifacts.s3.us-east-2.amazonaws.com/yolov4.tar.gz\n",
      "Resolving aws-ml-blog-artifacts.s3.us-east-2.amazonaws.com (aws-ml-blog-artifacts.s3.us-east-2.amazonaws.com)... 52.219.106.114\n",
      "Connecting to aws-ml-blog-artifacts.s3.us-east-2.amazonaws.com (aws-ml-blog-artifacts.s3.us-east-2.amazonaws.com)|52.219.106.114|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 239656714 (229M) [application/x-gzip]\n",
      "Saving to: ‘yolov4.tar.gz’\n",
      "\n",
      "yolov4.tar.gz       100%[===================>] 228.55M  41.1MB/s    in 5.4s    \n",
      "\n",
      "2021-09-21 19:31:20 (42.7 MB/s) - ‘yolov4.tar.gz’ saved [239656714/239656714]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_archive = 'yolov4.tar.gz'\n",
    "!wget https://aws-ml-blog-artifacts.s3.us-east-2.amazonaws.com/yolov4.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "compilation_job_name = name_from_base('torchvision-yolov4-neo-1')\n",
    "prefix = compilation_job_name+'/model'\n",
    "model_path = sess.upload_data(path=model_archive, key_prefix=prefix)\n",
    "compiled_model_path = 's3://{}/{}/output'.format(bucket, compilation_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---"
     ]
    }
   ],
   "source": [
    "# deploy endpoint\n",
    "\n",
    "framework_version = '1.6'\n",
    "py_version = 'py3'\n",
    "instance_type = 'ml.c5.9xlarge'\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "sm_model = PyTorchModel(\n",
    "    model_data=model_path,\n",
    "    framework_version=framework_version,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    entry_point='code/inference.py',\n",
    "    py_version=py_version,\n",
    "    env={\"COMPILEDMODEL\": 'False', 'MMS_MAX_RESPONSE_SIZE': '100000000', 'MMS_DEFAULT_RESPONSE_TIMEOUT': '500'}\n",
    ")\n",
    "\n",
    "uncompiled_predictor = sm_model.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type=instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_name = 'input0'\n",
    "input_shape = [1,3,416,416]\n",
    "data_shape = json.dumps({input_layer_name: input_shape})\n",
    "target_device = 'ml_c5'\n",
    "framework = 'PYTORCH'\n",
    "compiled_env = {\"MMS_DEFAULT_WORKERS_PER_MODEL\":'1', \"TVM_NUM_THREADS\": '36', \"COMPILEDMODEL\": 'True', 'MMS_MAX_RESPONSE_SIZE': '100000000', 'MMS_DEFAULT_RESPONSE_TIMEOUT': '500'}\n",
    "\n",
    "sm_model_compiled = PyTorchModel(\n",
    "    model_data=model_path,\n",
    "    framework_version = framework_version,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    entry_point='code/inference.py',\n",
    "    py_version=py_version,\n",
    "    env=compiled_env\n",
    ")\n",
    "\n",
    "compiled_model = sm_model_compiled.compile(\n",
    "    target_instance_family=target_device, \n",
    "    input_shape=data_shape,\n",
    "    job_name=compilation_job_name,\n",
    "    role=role,\n",
    "    framework=framework.lower(),\n",
    "    framework_version=framework_version,\n",
    "    output_path=compiled_model_path\n",
    ")\n",
    "\n",
    "optimized_predictor = compiled_model.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "\n",
    "iters = 1000\n",
    "warmup = 100\n",
    "client = boto3.client('sagemaker-runtime', region_name=region)\n",
    "\n",
    "content_type = 'application/x-image'\n",
    "\n",
    "sample_img_url = \"https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\"\n",
    "body = requests.get(sample_img_url).content\n",
    "   \n",
    "compiled_perf = []\n",
    "uncompiled_perf = []\n",
    "  \n",
    "for i in range(iters):\n",
    "    t0 = time.time()\n",
    "    response = client.invoke_endpoint(EndpointName=optimized_predictor.endpoint_name, Body=body, ContentType=content_type)\n",
    "    t1 = time.time()\n",
    "    #convert to millis\n",
    "    compiled_elapsed = (t1-t0)*1000\n",
    "\n",
    "    t0 = time.time()\n",
    "    response = client.invoke_endpoint(EndpointName=uncompiled_predictor.endpoint_name, Body=body, ContentType=content_type)\n",
    "    t1 = time.time()\n",
    "    #convert to millis\n",
    "    uncompiled_elapsed = (t1-t0)*1000\n",
    "    \n",
    "    if warmup == 0:\n",
    "        compiled_perf.append(compiled_elapsed)\n",
    "        uncompiled_perf.append(uncompiled_elapsed)\n",
    "    else:\n",
    "        print(f'warmup ({i}, {iters}) : c - {compiled_elapsed} ms . uc - {uncompiled_elapsed} ms')\n",
    "        warmup -= 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(compiled_perf, 'red')\n",
    "plt.plot(uncompiled_perf, 'blue')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Milliseconds')\n",
    "plt.legend([\"Compiled\", \"Uncompiled\"], loc=0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
